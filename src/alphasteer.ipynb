{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4d8d6763",
      "metadata": {
        "id": "4d8d6763"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import subprocess\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p \"/content/drive/MyDrive/Colab Projects\"\n",
        "%cd \"/content/drive/MyDrive/Colab Projects\"\n",
        "\n",
        "!git clone https://github.com/sudden-deaf/AlphaSteer.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPOmasOkXw__",
        "outputId": "04b3d97d-3bf6-4a3e-f8b7-803a3566d1cc"
      },
      "id": "FPOmasOkXw__",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Projects\n",
            "fatal: destination path 'AlphaSteer' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Projects/AlphaSteer/src\"\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhaIqU4ZYT4Z",
        "outputId": "d6327acd-39fc-4d47-bf5b-9b55b4d9c948"
      },
      "id": "lhaIqU4ZYT4Z",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Projects/AlphaSteer/src\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from extract_embeddings import extract_embeddings_main\n",
        "from calc_steering_matrix import calc_steering_main"
      ],
      "metadata": {
        "id": "xlHOJmfSYC-z"
      },
      "id": "xlHOJmfSYC-z",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Projects/AlphaSteer/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD99_-sRZNZi",
        "outputId": "e718bab4-c231-4202-a7ae-3fc1538f2845"
      },
      "id": "oD99_-sRZNZi",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Projects/AlphaSteer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ade37e5",
      "metadata": {
        "id": "0ade37e5"
      },
      "source": [
        "======================\n",
        "Configuration\n",
        "======================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "332b2b25",
      "metadata": {
        "id": "332b2b25"
      },
      "outputs": [],
      "source": [
        "TRAIN_VAL_DIR = \"data/instructions/train_val\"\n",
        "EMBEDDING_DIR = \"data/embeddings/TinyLlama\"\n",
        "NICKNAME = \"TinyLlama\"\n",
        "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "DEVICE = \"cuda:0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "eecc8d14",
      "metadata": {
        "id": "eecc8d14"
      },
      "outputs": [],
      "source": [
        "STEERING_SAVE_PATH = f\"data/steering_matrix/steering_matrix_{NICKNAME}.pt\"\n",
        "GENERATE_CONFIG_DIR = \"config/TinyLlama\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5abd6121",
      "metadata": {
        "id": "5abd6121"
      },
      "outputs": [],
      "source": [
        "# Ensure output directories exist\n",
        "os.makedirs(EMBEDDING_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.dirname(STEERING_SAVE_PATH), exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc93d623",
      "metadata": {
        "id": "cc93d623"
      },
      "source": [
        "======================\n",
        "Extract embeddings\n",
        "======================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "16107f77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16107f77",
        "outputId": "7504bc49-8e43-4efd-dc44-c94e752396e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data/instructions/train_val/benign_train.json', 'data/instructions/train_val/benign_val.json', 'data/instructions/train_val/borderline_val.json', 'data/instructions/train_val/coconot_original.json', 'data/instructions/train_val/coconot_pref.json', 'data/instructions/train_val/harmful_train_1000.json', 'data/instructions/train_val/harmful_val.json', 'data/instructions/train_val/jailbreak_train.json']\n"
          ]
        }
      ],
      "source": [
        "json_files = glob.glob(os.path.join(TRAIN_VAL_DIR, \"*.json\"))\n",
        "print(json_files)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "HF_TOKEN=userdata.get('HF_TOKEN')\n",
        "\n",
        "if HF_TOKEN:\n",
        "    login(HF_TOKEN)\n",
        "    print(\"Successfully logged in to Hugging Face!\")\n",
        "else:\n",
        "    print(\"Token is not set. Please save the token first.\")"
      ],
      "metadata": {
        "id": "MgdZgrW1ia-R",
        "outputId": "fbafc420-d9f8-493e-b19a-cd107544c666",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MgdZgrW1ia-R",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully logged in to Hugging Face!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d2a8580b",
      "metadata": {
        "lines_to_next_cell": 0,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2a8580b",
        "outputId": "e55061b0-b235-47ff-db44-96e098e92171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting embeddings for data/instructions/train_val/benign_train.json\n",
            "Extracting embeddings for data/instructions/train_val/benign_val.json\n",
            "Extracting embeddings for data/instructions/train_val/borderline_val.json\n",
            "Extracting embeddings for data/instructions/train_val/coconot_original.json\n",
            "Extracting embeddings for data/instructions/train_val/coconot_pref.json\n",
            "Extracting embeddings for data/instructions/train_val/harmful_train_1000.json\n",
            "Extracting embeddings for data/instructions/train_val/harmful_val.json\n",
            "Extracting embeddings for data/instructions/train_val/jailbreak_train.json\n"
          ]
        }
      ],
      "source": [
        "for file_path in json_files:\n",
        "    filename = Path(file_path).stem\n",
        "    print(f\"Extracting embeddings for {file_path}\")\n",
        "\n",
        "    # Match bash logic\n",
        "    if \"coconot\" in filename:\n",
        "        prompt_column = \"prompt\"\n",
        "    else:\n",
        "        prompt_column = \"query\"\n",
        "\n",
        "    output_file = os.path.join(EMBEDDING_DIR, f\"embeds_{filename}.pt\")\n",
        "    extract_embeddings_main(\n",
        "        model_name=MODEL_NAME,\n",
        "        input_file=file_path,\n",
        "        prompt_column=prompt_column,\n",
        "        output_file=output_file,\n",
        "        batch_size=16,\n",
        "        device=DEVICE\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b35cb76e",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "b35cb76e"
      },
      "source": [
        "======================\n",
        "Calculate steering matrix\n",
        "======================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6439fd10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "6439fd10",
        "outputId": "4a9e01a3-e6be-4c95-a9da-c09ce85aeaa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating steering matrix for TinyLlama\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'TinyLlama/TinyLlama-1.1B-Chat-v1.0'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2985794299.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mSTEERING_SAVE_PATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data/steering_matrix/steering_matrix_${NICKNAME}.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m calc_steering_main(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0membedding_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEMBEDDING_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Colab Projects/AlphaSteer/src/calc_steering_matrix.py\u001b[0m in \u001b[0;36mcalc_steering_main\u001b[0;34m(embedding_dir, model_name, save_path, device)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0membeds_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Get layer-specific configuration (layer number and nullspace ratio)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mlayers_ratio_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlphaSteer_CALCULATION_CONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Load benign embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'"
          ]
        }
      ],
      "source": [
        "print(f\"Calculating steering matrix for {NICKNAME}\")\n",
        "STEERING_SAVE_PATH=\"data/steering_matrix/steering_matrix_${NICKNAME}.pt\"\n",
        "\n",
        "calc_steering_main(\n",
        "    embedding_dir=EMBEDDING_DIR,\n",
        "    model_name=MODEL_NAME,\n",
        "    save_path=STEERING_SAVE_PATH,\n",
        "    device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0d6437b",
      "metadata": {
        "id": "e0d6437b"
      },
      "source": [
        "# ======================\n",
        "# Generate responses\n",
        "# ======================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9da275eb",
      "metadata": {
        "id": "9da275eb"
      },
      "outputs": [],
      "source": [
        "print(f\"Generating responses for {NICKNAME}\")\n",
        "yaml_files = glob.glob(os.path.join(GENERATE_CONFIG_DIR, \"*.yaml\"))\n",
        "for yaml_path in yaml_files:\n",
        "    print(f\"Generating response for {yaml_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b9ccfe2",
      "metadata": {
        "id": "0b9ccfe2"
      },
      "source": [
        "    subprocess.run(\n",
        "        [\n",
        "            \"python\",\n",
        "            \"src/generate_response.py\",\n",
        "            \"--config_path\", yaml_path,\n",
        "        ],\n",
        "        check=True,\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "formats": "ipynb,py:percent",
      "main_language": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}